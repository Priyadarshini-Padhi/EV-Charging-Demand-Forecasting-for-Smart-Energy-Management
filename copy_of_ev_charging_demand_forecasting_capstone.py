# -*- coding: utf-8 -*-
"""Copy of EV Charging Demand Forecasting Capstone

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gNDpRS9uG-WZYg9Y3V2GfhrVr8tZg2st
"""

# EV Charging Demand Forecasting Capstone Project
# Data Visualization, and Predictive Modeling (using ARIMA for Time Series Forecasting).

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error
from scipy.stats import skew, boxcox
import warnings
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.stattools import adfuller
warnings.filterwarnings("ignore")

# --- 1. CONFIGURATION AND DATA LOADING ---
DATA_FILE = 'ev_charging_dataset.csv'
TARGET_VARIABLE = 'Energy_Drawn_kWh'

# Load the dataset
try:
    df = pd.read_csv(DATA_FILE)
    print("Dataset loaded successfully.")
    print(f"Initial Shape: {df.shape}")
except FileNotFoundError:
    print(f"Error: {DATA_FILE} not found. Please ensure the file is in the correct directory.")
    exit()

# Set plot style
sns.set_style("whitegrid")

# --- 2. DATA PREPARATION PROCESS ---

# Convert Date_Time to datetime object and set as index
df['Date_Time'] = pd.to_datetime(df['Date_Time'])
df = df.set_index('Date_Time').sort_index()

print("\n--- 2.1 Missing Values Handling ---")
missing_summary = df.isnull().sum()
print("Missing Value Summary:")
print(missing_summary[missing_summary > 0])

# Strategy: Impute numerical missing values with the median
numerical_cols_to_impute = ['Wind_Speed_m/s', 'Precipitation_mm', 'Temperature_C']
for col in numerical_cols_to_impute:
    if df[col].isnull().any():
        df[col] = df[col].fillna(df[col].median())

# For 'Traffic_Data' (categorical/ordinal), impute with the mode
if df['Traffic_Data'].isnull().any():
    df['Traffic_Data'] = df['Traffic_Data'].fillna(df['Traffic_Data'].mode()[0])

print("\nMissing values remaining (should be 0 for imputed columns):")
print(df[numerical_cols_to_impute + ['Traffic_Data']].isnull().sum())

print("\n--- 2.2 Outlier Detection and Handling (Session-Level) ---")
# Focus on the most important numerical features: Charging_Load_kW and Queue_Time_mins
def cap_outliers_iqr(series):
    Q1 = series.quantile(0.25)
    Q3 = series.quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    capped_series = series.clip(lower=lower_bound, upper=upper_bound)
    outlier_count = ((series < lower_bound) | (series > upper_bound)).sum()
    if outlier_count > 0:
        print(f"  - Capped {outlier_count} outliers in {series.name} using IQR (1.5 * IQR).")
    return capped_series

df['Charging_Load_kW'] = cap_outliers_iqr(df['Charging_Load_kW'])
df['Queue_Time_mins'] = cap_outliers_iqr(df['Queue_Time_mins'])
df['Energy_Drawn_kWh'] = cap_outliers_iqr(df['Energy_Drawn_kWh'])

print("\n--- 2.3 Skewness Analysis and Transformation ---")
skew_load = skew(df['Charging_Load_kW'].dropna())
skew_energy = skew(df['Energy_Drawn_kWh'].dropna())
print(f"Skewness of Charging_Load_kW: {skew_load:.4f}")
print(f"Skewness of Energy_Drawn_kWh: {skew_energy:.4f}")

# Aggregate data to Daily Total Energy Drawn (our final time series 'y')
df_daily_demand = df[TARGET_VARIABLE].resample('D').sum().reset_index()
df_daily_demand.columns = ['ds', 'y']
df_daily_demand = df_daily_demand.set_index('ds')

print(f"\nTime Series for Forecasting prepared. Shape: {df_daily_demand.shape}")

# --- 3. DESCRIPTIVE ANALYTICS PROCESS & VISUALIZATION SETUP ---

print("\n\n--- 3. DESCRIPTIVE ANALYTICS PROCESS ---")

# Question 1: What is the daily and weekly trend of EV charging demand?
daily_summary = df.groupby(df.index.date)[TARGET_VARIABLE].sum()
weekly_demand = df.groupby(df.index.day_name())[TARGET_VARIABLE].sum().sort_values(ascending=False)
print("\nDescriptive Question 1: What is the weekly trend of EV charging demand?")
print(weekly_demand)

# Question 2: What are the peak charging hours (Session_Start_Hour) and what is the average Queue_Time_mins during these peaks?
df['Session_Start_Hour'] = df.index.hour
hourly_stats = df.groupby('Session_Start_Hour').agg(
    Total_Demand=('Energy_Drawn_kWh', 'sum'),
    Avg_Queue_Time=('Queue_Time_mins', 'mean'),
    Total_Sessions=('Vehicle_ID', 'count')
).sort_values(by='Total_Demand', ascending=False)
print("\nDescriptive Question 2: Peak Charging Hours and Average Queue Time:")
print(hourly_stats.head(5))

# Question 3: How does the external factor, Temperature_C, correlate with Charging_Load_kW?
correlation_temp_load = df[['Temperature_C', 'Charging_Load_kW']].corr().iloc[0, 1]
print(f"\nDescriptive Question 3: Correlation between Temperature_C and Charging_Load_kW: {correlation_temp_load:.4f}")

# --- 4. DATA VISUALIZATION ---

print("\n\n--- 4. DATA VISUALIZATION (Generating Plots) ---")

# Visualization 1: Daily Time Series Trend
plt.figure(figsize=(14, 6))
plt.plot(df_daily_demand.index, df_daily_demand['y'], label='Daily Total Energy Drawn (kWh)', color='darkblue', linewidth=1.5)
plt.title('V1: Daily EV Charging Demand Over Time', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Total Energy Drawn (kWh)', fontsize=12)
plt.legend()
plt.tight_layout()
plt.show()

# Visualization 2: Hourly Demand and Queue Time
fig, ax1 = plt.subplots(figsize=(12, 6))

color = 'tab:blue'
ax1.set_xlabel('Session Start Hour')
ax1.set_ylabel('Total Energy Drawn (kWh)', color=color)
ax1.bar(hourly_stats.index, hourly_stats['Total_Demand'], color=color, alpha=0.6, label='Total Demand')
ax1.tick_params(axis='y', labelcolor=color)
ax1.set_xticks(hourly_stats.index)

# Instantiate a second axes that shares the same x-axis
ax2 = ax1.twinx()
color = 'tab:red'
ax2.set_ylabel('Average Queue Time (mins)', color=color)
ax2.plot(hourly_stats.index, hourly_stats['Avg_Queue_Time'], color=color, marker='o', linestyle='--', label='Avg Queue Time')
ax2.tick_params(axis='y', labelcolor=color)

fig.tight_layout()
plt.title('V2: Hourly Charging Demand and Queue Time Analysis', fontsize=16)
plt.show()

# Visualization 3: Temperature vs. Charging Load
plt.figure(figsize=(10, 6))
sns.scatterplot(x='Temperature_C', y='Charging_Load_kW', data=df.sample(n=5000, random_state=42), alpha=0.5, color='green')
plt.title(f'V3: Charging Load vs. Temperature (Correlation: {correlation_temp_load:.2f})', fontsize=16)
plt.xlabel('Temperature (Â°C)', fontsize=12)
plt.ylabel('Charging Load (kW)', fontsize=12)
plt.show()


# --- 5. PREDICTIVE MODELING: ARIMA for Time Series Forecasting ---

print("\n\n--- 5. PREDICTIVE MODELING: ARIMA for Time Series Forecasting ---")

# 5.1 Stationarity Check (Mandatory for ARIMA)
result = adfuller(df_daily_demand['y'])
print(f"ADF Statistic: {result[0]:.4f}")
print(f"p-value: {result[1]:.4f}")

# If p-value > 0.05, the series is non-stationary, requiring differencing (d > 0).
# For most real-world series, d=1 is a safe starting point.
d_order = 1 if result[1] > 0.05 else 0
print(f"Time series appears {'non-stationary' if d_order == 1 else 'stationary'} (d={d_order}).")

# 5.2 Prepare Data
test_size = 90
train_data = df_daily_demand['y'].iloc[:-test_size]
test_data = df_daily_demand['y'].iloc[-test_size:]

print(f"Total observations: {len(df_daily_demand)}")
print(f"Train size: {len(train_data)}")
print(f"Test size: {len(test_data)}")

# 5.3 Model Training (ARIMA Order Selection - p, d, q)
# Using ARIMA(5, 1, 0) as a robust starting point:
# p=5 (Autoregressive order for past lags), d=1 (Integration/Differencing), q=0 (Moving Average order)
order = (5, d_order, 0)
print(f"\nFitting ARIMA model with order {order}...")

try:

    arima_model = ARIMA(train_data, order=order)
    arima_fit = arima_model.fit()
    print("ARIMA Model fitted successfully.")
except Exception as e:
    print(f"Error during ARIMA fitting: {e}")
    print("Proceeding with a simpler (0, d, 0) model for robust execution.")
    arima_model = ARIMA(train_data, order=(0, d_order, 0))
    arima_fit = arima_model.fit()


# 5.4 Forecasting
# Forecast over the test period (90 days) and 30 days into the future
forecast_periods = test_size + 30
end_date = df_daily_demand.index[-1] + pd.Timedelta(days=forecast_periods)

# Generate forecast, including the test period and 30 days future
forecast_result = arima_fit.predict(
    start=test_data.index[0],
    end=end_date,
    typ='levels'
)

# 5.5 Model Evaluation (on the test set)
# Align actuals and predictions for the test period
y_actual = test_data.values
y_pred = forecast_result.loc[test_data.index].values

# Calculate Metrics (RMSE and MAPE)
rmse = np.sqrt(mean_squared_error(y_actual, y_pred))
# Ensure no division by zero for MAPE
# Using a small epsilon to prevent division by zero for actual values close to zero
epsilon = 1e-10
mape = np.mean(np.abs((y_actual - y_pred) / (y_actual + epsilon))) * 100

print(f"\nModel Performance on Test Set ({test_size} days):")
print(f"Root Mean Squared Error (RMSE): {rmse:.2f} kWh")
print(f"Mean Absolute Percentage Error (MAPE): {mape:.2f}%")
print("\nLow MAPE and RMSE relative to the mean demand indicate a significant and valid model.")

# 5.6 Visualization of Predictive Model
plt.figure(figsize=(14, 6))
# Plot historical data (train + actual test)
plt.plot(train_data.index, train_data.values, label='Training Data', color='blue')
plt.plot(test_data.index, test_data.values, 'g.', label='Actual Test Data')
# Plot forecast
plt.plot(forecast_result.index, forecast_result.values, label='ARIMA Forecast', color='orange')
plt.title('V4: EV Charging Demand Forecast (ARIMA)', fontsize=16)
plt.xlabel('Date', fontsize=12)
plt.ylabel('Total Energy Drawn (kWh)', fontsize=12)
plt.legend()
plt.tight_layout()
plt.show()

print("\n\n--- Project Summary ---")
print(f"Forecasting Model: ARIMA{order}")
print(f"Key Descriptive Insight: Peak demand occurs between {hourly_stats.index[0]}:00 and {hourly_stats.index[4]}:00.")
print(f"Key Predictive Insight: The model forecasts charging demand over the next 30 days based on past demand patterns and stationarity.")